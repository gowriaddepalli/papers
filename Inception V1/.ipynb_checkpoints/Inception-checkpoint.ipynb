{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hddpB7Iu8ynD"
      },
      "source": [
        "# Implementation of InceptioNet\n",
        "> In this notebook  I have implemented InceptinNet from scratch using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYlM3FI-8mZK"
      },
      "source": [
        "#importing libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwerA9Bw1BZb"
      },
      "source": [
        "class InceptionNet(nn.Module):\n",
        "    def __init__(self,aux_logits=True,num_classes=1000):\n",
        "        super(InceptionNet, self).__init__()\n",
        "        assert aux_logits == True or aux_logits == False\n",
        "        self.aux_logits = aux_logits\n",
        "\n",
        "        self.conv1 = conv_block(in_channels=3,out_channels=64,kernel_size=(7,7),\n",
        "                                stride=(2,2), padding=(3,3))\n",
        "        \n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2, padding=1)\n",
        "        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3,stride=2, padding=1)\n",
        "        \n",
        "        # In this order: in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n",
        "        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=(3,3),stride=2, padding=1)\n",
        "        \n",
        "        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3,stride=2, padding=1)\n",
        "        \n",
        "        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "        \n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=7,stride=1)\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.fc1 = nn.Linear(1024, 1000)\n",
        "        \n",
        "        if self.aux_logits:\n",
        "          self.aux1 = InceptionAux(512, num_classes)\n",
        "          self.aux2 = InceptionAux(528, num_classes)\n",
        "        else:\n",
        "          self.aux1 = self.aux2 = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        \n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "        \n",
        "        x = self.inception4a(x)\n",
        "        \n",
        "        # Auxiliary Softmax classifier 1\n",
        "        if self.aux_logits and self.training:\n",
        "          aux1 = self.aux1(x)\n",
        "            \n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        \n",
        "        ## Auxiliary Softmax classifier 2\n",
        "        if self.aux_logits and self.training:\n",
        "          aux2 = self.aux2(x)\n",
        "            \n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        \n",
        "        if self.aux_logits and self.training:\n",
        "            return aux1, aux2, x\n",
        "        else:\n",
        "            return x\n",
        "    \n",
        "        \n",
        "class Inception_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
        "        super(Inception_block, self).__init__()\n",
        "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=(1,1))\n",
        "        \n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, red_3x3, kernel_size=(1,1)),\n",
        "            conv_block(red_3x3, out_3x3, kernel_size=(3,3),padding=(1,1))\n",
        "            )\n",
        "        \n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, red_5x5, kernel_size=(1,1)),\n",
        "            conv_block(red_5x5, out_5x5, kernel_size=(5,5),padding=(2,2))\n",
        "            )\n",
        "    \n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=(3,3),stride=(1,1),padding=(1,1)),\n",
        "            conv_block(in_channels,out_1x1pool,kernel_size=(1,1))\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
        "    \n",
        "class InceptionAux(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(InceptionAux,self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.7)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=5,stride=3)\n",
        "        self.conv = conv_block(in_channels, 128, kernel_size=1)\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.conv(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(conv_block, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.relu(self.batchnorm(self.conv(x)))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAyfJzPP0lRS",
        "outputId": "e0580bc8-7687-4b68-e6a0-bef61cde8b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def test():\n",
        "    net = InceptionNet(aux_logits=True,num_classes=1000)\n",
        "    x = torch.randn(3,3,224,224)\n",
        "    y = net(x)\n",
        "    print(y)\n",
        "test()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 0.0559, -0.1440,  0.2350,  ...,  0.4331,  0.1717, -0.0125],\n",
            "        [-0.3293, -0.0967, -0.6391,  ..., -0.5537,  0.2526, -0.0736],\n",
            "        [ 0.4002, -0.3521, -0.3439,  ...,  0.1489,  0.0598, -0.4173]],\n",
            "       grad_fn=<AddmmBackward>), tensor([[-0.0082,  0.0710,  0.1351,  ...,  0.1535,  0.0231, -0.1121],\n",
            "        [ 0.2723, -0.0473, -0.1062,  ..., -0.2266, -0.2847,  0.1736],\n",
            "        [-0.3326,  0.3766, -0.0156,  ...,  0.5092,  0.2348,  0.1173]],\n",
            "       grad_fn=<AddmmBackward>), tensor([[ 0.0371,  0.0758,  0.0309,  ..., -0.1207,  0.0175,  0.0784],\n",
            "        [-0.5471,  0.2341, -0.0349,  ...,  0.0780, -0.6453, -0.3441],\n",
            "        [-0.6387,  0.1350, -0.2928,  ...,  0.3331, -0.0562, -0.0400]],\n",
            "       grad_fn=<AddmmBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNlDFB7xdQ-G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}